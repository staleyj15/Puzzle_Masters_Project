{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ImgPrep import file_names, read_img, reshape_array, split_img, remove_background, fix_edges, flatten_arrays, glcmm\n",
    "from ImgCluster import cluster_pixels, cluster_pieces, silhouette_analysis, optimalK\n",
    "from Funcs4Testing import display_cluster_imgs, display_img, img_scatter, plot_silhouette_analysis, plot_gap_stats\n",
    "from sklearn.manifold import Isomap\n",
    "from sklearn.cluster import KMeans, SpectralClustering\n",
    "from sklearn.decomposition import PCA\n",
    "from networkx.convert import to_networkx_graph as ToGraph\n",
    "from collections import defaultdict\n",
    "import cdlib\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "#### SET GLOBAL VARIABLES HERE\n",
    "# -------------------------\n",
    "\n",
    "puzzle_folder = 'puzzle_2'\n",
    "load_from_pickle = True # set to True to load feature set from pickle file, otherwise set to False and generate feature set\n",
    "\n",
    "# -------------------------\n",
    "###########################\n",
    "\n",
    "# list of files to read in\n",
    "scan_directory = 'puzzle_scans/' + puzzle_folder\n",
    "files = file_names(scan_directory)\n",
    "pictures = [] # picture arrays\n",
    "bgremoved = [] # pic arrays with scanner background removed\n",
    "avg_rgb_pieces = [] # avg rgp of the entire puzzle piece\n",
    "pic_arrays = [] # flattened pic arrays\n",
    "pic_arrays_filtered = [] # flattened pic arrays w/ [0,0,0] pixels filtered out\n",
    "features = []\n",
    "\n",
    "for i in range(1, len(files) + 1):\n",
    "    \n",
    "    # store picture as array\n",
    "    pic = read_img(files, i)\n",
    "\n",
    "    # split each image into 20 pieces\n",
    "    pieces = split_img(pic, 5, 4)\n",
    "    pictures += pieces\n",
    "    assert all([piece.shape for piece in pieces]), 'All arrays are not the same size'\n",
    "\n",
    "shape = pieces[0].shape\n",
    "\n",
    "# generate features for data points\n",
    "\n",
    "if load_from_pickle is True:\n",
    "    filename = 'pickle_files/' + puzzle_folder + '/feature_set.pkl'\n",
    "    feature_set = joblib.load(filename)\n",
    "else:\n",
    "    for indx,img in enumerate(pictures):\n",
    "        # remove background\n",
    "        pic_bgremoved = remove_background(img)\n",
    "        pic_bgremoved = fix_edges(pic_bgremoved, indx, shape)\n",
    "        assert pic_bgremoved.shape == img.shape, \\\n",
    "            'Picture with background removed is not the same size as original picture'\n",
    "        bgremoved.append(pic_bgremoved)\n",
    "\n",
    "        # flatten picture array\n",
    "        flat_pic = reshape_array(pic_bgremoved, starting_dim = len(pic_bgremoved.shape))\n",
    "        assert flat_pic.shape[0] == img.shape[0] * img.shape[1], \\\n",
    "            'Flattened picture does not have the same number of pixels as original picture'\n",
    "        pic_arrays.append(flat_pic)\n",
    "\n",
    "        # find average rgb of entire piece\n",
    "        keep_indices = np.where(np.sum(flat_pic, axis = 1) > 0)[0]\n",
    "        flat_pic_filtered = flat_pic[keep_indices]\n",
    "        pic_arrays_filtered.append(flat_pic_filtered)\n",
    "        avg_rgb_pieces.append(np.mean(flat_pic_filtered, axis = 0))\n",
    "\n",
    "    assert len(bgremoved) == len(pictures), \\\n",
    "        'List of pictures with background removed is not the same size as original list of pictures'\n",
    "    assert len(pic_arrays_filtered) == len(pictures), \\\n",
    "        'List of flattened picture arrays is not the same size as original list of pictures'\n",
    "    assert len(avg_rgb_pieces) == len(pictures), \\\n",
    "        'Quantity of average rgb values % quantity of puzzle pieces' % ('exceeds' if len(avg_rgb_pieces) > len(pictures) else 'is less than')\n",
    "\n",
    "    # Find RGB values of cluster centers for each puzzle piece\n",
    "    clustered_pixels = cluster_pixels(pixels = pic_arrays_filtered, n_clusters = 3)\n",
    "\n",
    "    # flatten cluster centers to use in features\n",
    "    centers_flattened = flatten_arrays(clustered_pixels)\n",
    "\n",
    "    # find texture features   \n",
    "    txtr_features = np.empty((len(bgremoved),24))\n",
    "    for indx,img in enumerate(bgremoved):\n",
    "        txtr_features[indx] = glcmm(img)\n",
    "\n",
    "    # concatenate all features for clustering pieces\n",
    "    feature_set =  np.concatenate((avg_rgb_pieces, centers_flattened, txtr_features), axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate gap-statistic to determine optimal k for clustering\n",
    "k, gapdf = optimalK(feature_set, maxClusters = 10)\n",
    "print(f'Optimal k is: {k}')\n",
    "\n",
    "plot_gap_stats(gapdf, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform Isomap and PCA on final feature set\n",
    "km_iso_models = defaultdict(dict)\n",
    "km_pca_models = defaultdict(dict)\n",
    "\n",
    "for i in range(2, 15):\n",
    "    # perform KMeans clustering on isomap reduction\n",
    "    iso_name = 'isoKM_' + str(i)\n",
    "    iso = Isomap(n_components = i).fit_transform(feature_set)\n",
    "    km_iso_models[iso_name]['reduced_features'] = iso\n",
    "    km_iso_models[iso_name]['model'] = KMeans(n_clusters = k).fit(iso)\n",
    "    \n",
    "    # perform KMeans clustering on pca reduction\n",
    "    pca_name = 'pcaKM_' + str(i)\n",
    "    pca = PCA(n_components = i).fit_transform(feature_set)\n",
    "    km_pca_models[pca_name]['reduced_features'] = pca\n",
    "    km_pca_models[pca_name]['model'] = KMeans(n_clusters = k).fit(pca)\n",
    "\n",
    "# perform k-means clustering on all features\n",
    "km = KMeans(n_clusters = k).fit(feature_set)\n",
    "\n",
    "# Spectral clustering on all features\n",
    "sc = SpectralClustering(n_clusters = k, assign_labels = \"discretize\", random_state = 5).fit(feature_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Goodness of Fit\n",
    "[Evaluation metrics provided by 'cdlib' package](https://cdlib.readthedocs.io/en/latest/reference/classes/node_clustering.html#methods)\n",
    "<br>\n",
    "[Additional cdlib documentation](https://cdlib.readthedocs.io/_/downloads/en/stable/pdf/)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare clusters to adjacency graph\n",
    "adjacency_path = 'AdjacencyMatrices/' + puzzle_folder.replace('_','').replace('p','P') + '_AdjacencyMatrix.csv'\n",
    "adj = np.loadtxt(adjacency_path, delimiter = ',', dtype=int)\n",
    "assert adj.shape[0] == adj.shape[1], 'Adjacency matrix must be symmetrical'\n",
    "assert adj.shape[0] == len(pictures), 'Adjacency matrix should have one row and one column for every puzzle piece'\n",
    "\n",
    "# Convert the adjacency matrix into a NetworkX graph object\n",
    "adjG = ToGraph(adj)\n",
    "\n",
    "# store indices of each cluster in list of lists\n",
    "model_dict = defaultdict(dict)\n",
    "all_models = [km, sc] + [km_iso_models[x]['model'] for x in km_iso_models] + [km_pca_models[x]['model'] for x in km_pca_models]\n",
    "all_names = ['KMeans', 'SpectralClustering'] + list(km_iso_models.keys()) + list(km_pca_models.keys())\n",
    "\n",
    "# create data frame to store comparison results\n",
    "model_comparison = pd.DataFrame({'model_name': all_names, 'modularity_score' : [0] * len(all_names), 'conductance_score': [0] * len(all_names)})\n",
    "\n",
    "for name,model in zip(all_names, all_models):\n",
    "    \n",
    "    clusters = []\n",
    "    \n",
    "    for i in range(k):\n",
    "        i_indices = np.where(model.labels_ == i)[0].tolist()\n",
    "        clusters.append(i_indices)\n",
    "    model_dict[name]['clusters'] = clusters\n",
    "    \n",
    "    Comms = cdlib.NodeClustering(clusters, adjG, 'Manual')\n",
    "    model_dict[name]['Comms'] = Comms\n",
    "    \n",
    "    # Using the object created above, many 'fitness' metrics can be calculated\n",
    "    modularity = cdlib.evaluation.newman_girvan_modularity(adjG, Comms)\n",
    "    conductance = cdlib.evaluation.conductance(adjG, Comms)\n",
    "    model_comparison.loc[model_comparison.model_name == name, ['modularity_score','conductance_score']] = [round(x,4) for x in [modularity.score, conductance.score]]\n",
    "\n",
    "model_comparison.sort_values(by = ['modularity_score', 'conductance_score'], ascending = [False, True], inplace = True)\n",
    "model_comparison.reset_index(drop = True, inplace = True)\n",
    "model_comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visual check of best performing model\n",
    "model2viz = model_comparison.iloc[0,0]\n",
    "selectedDict = km_iso_models if re.search(r'iso', model2viz) is not None else km_pca_models\n",
    "savepath = puzzle_folder.replace('_','') + '_isoKM_2plot'\n",
    "img_scatter(selectedDict['isoKM_2']['reduced_features'], pictures, 60, save = False, filename = savepath)\n",
    "\n",
    "# identify smallest clusters\n",
    "_, count = np.unique(selectedDict[model2viz]['model'].labels_, return_counts=True)\n",
    "display_clusters = np.argsort(count)[:3]\n",
    "\n",
    "# visual inspection of KMeans clusters\n",
    "cluster = display_clusters[2]\n",
    "for indx in np.where(selectedDict[model2viz]['model'].labels_ == cluster)[0]:\n",
    "    save_pic_path = puzzle_folder.replace('_','') + '_cluster' + str(cluster) + '_img' + str(indx)\n",
    "    display_img(pictures[indx], save = False, filename = save_pic_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
